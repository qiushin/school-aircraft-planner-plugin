#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ— äººæœºè§†é¢‘AIè¯†åˆ«ç³»ç»Ÿ
ä½¿ç”¨YOLO11è¿›è¡Œç›®æ ‡æ£€æµ‹ï¼Œè¯†åˆ«äººæµã€äº•ç›–ã€ç”µç“¶è½¦ã€æººæ°´ç‚¹ç­‰
"""

import cv2
import numpy as np
import json
import socket
import time
import threading
import argparse
import logging
import base64
from datetime import datetime
from pathlib import Path
import random

try:
    from ultralytics import YOLO
    YOLO_AVAILABLE = True
except ImportError:
    YOLO_AVAILABLE = False
    print("Warning: ultralytics not available, using simulation mode")

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('yolo_detection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class DroneVideoDetector:
    """æ— äººæœºè§†é¢‘æ£€æµ‹å™¨"""
    
    def __init__(self, model_path=None, host='localhost', port=8888):
        self.host = host
        self.port = port
        self.socket = None
        self.running = False
        
        # æ£€æµ‹ç±»åˆ«æ˜ å°„
        self.class_mapping = {
            'person': 'person',
            'bicycle': 'bicycle', 
            'motorcycle': 'motorcycle',
            'car': 'car',
            'truck': 'truck',
            'bus': 'bus'
        }
        
        # æ›´æ–°çš„é£é™©è¯„ä¼°è§„åˆ™
        self.risk_rules = {
            'person': {
                'max_safe_count': 20,  # è¶…è¿‡20äººä¸ºé«˜é£é™©
                'water_safe_distance': 2.0,  # æ°´åŸŸ2ç±³èŒƒå›´å†…æœ‰äººä¸ºé«˜é£é™©
                'confidence_threshold': 0.3  # é™ä½é˜ˆå€¼ï¼Œæé«˜æ£€æµ‹æ•æ„Ÿåº¦
            },
            'bicycle': {
                'count_only': True,  # ä»…ç»Ÿè®¡æ•°é‡
                'confidence_threshold': 0.3  # é™ä½é˜ˆå€¼
            },
            'motorcycle': {
                'count_only': True,  # ä»…ç»Ÿè®¡æ•°é‡
                'confidence_threshold': 0.3  # é™ä½é˜ˆå€¼
            },
            'car': {
                'count_only': True,  # ä»…ç»Ÿè®¡æ•°é‡
                'confidence_threshold': 0.4
            },
            'truck': {
                'count_only': True,  # ä»…ç»Ÿè®¡æ•°é‡
                'confidence_threshold': 0.4
            },
            'bus': {
                'count_only': True,  # ä»…ç»Ÿè®¡æ•°é‡
                'confidence_threshold': 0.4
            },
            'manhole': {
                'count_only': True,  # ä»…ç»Ÿè®¡æ•°é‡
                'confidence_threshold': 0.4
            }
        }
        
        # æ°´åŸŸåŒºåŸŸå®šä¹‰ (å¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´åæ ‡)
        self.water_areas = [
            # (x, y, width, height) - å¯ä»¥å®šä¹‰å¤šä¸ªæ°´åŸŸåŒºåŸŸ
            # ç¤ºä¾‹æ°´åŸŸåŒºåŸŸï¼Œæ‚¨å¯ä»¥æ ¹æ®å®é™…è§†é¢‘å†…å®¹è°ƒæ•´
        ]
        
        # åˆå§‹åŒ–YOLOæ¨¡å‹
        self.model = None
        if YOLO_AVAILABLE:
            try:
                if model_path and Path(model_path).exists():
                    self.model = YOLO(model_path)
                else:
                    # å°è¯•ä½¿ç”¨æ›´ç²¾ç¡®çš„æ¨¡å‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™é™çº§åˆ°nanoç‰ˆæœ¬
                    try:
                        self.model = YOLO('yolo11s.pt')  # ä½¿ç”¨smallç‰ˆæœ¬ï¼Œæ›´ç²¾ç¡®
                        logger.info("YOLOæ¨¡å‹åŠ è½½æˆåŠŸ (yolo11s.pt - ç²¾ç¡®ç‰ˆ)")
                    except:
                        self.model = YOLO('yolo11n.pt')  # é™çº§åˆ°nanoç‰ˆæœ¬
                        logger.info("YOLOæ¨¡å‹åŠ è½½æˆåŠŸ (yolo11n.pt - å¿«é€Ÿç‰ˆ)")
            except Exception as e:
                logger.error(f"YOLOæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
                self.model = None
        
        # æ£€æµ‹ç»Ÿè®¡
        self.detection_stats = {
            'total_frames': 0,
            'total_detections': 0,
            'person_count': 0,
            'bicycle_count': 0,
            'motorcycle_count': 0,
            'car_count': 0,
            'truck_count': 0,
            'bus_count': 0,
            'manhole_count': 0,
            'risk_alerts': 0,
            'start_time': datetime.now()
        }
        
        # å½“å‰å¸§çš„æ£€æµ‹è®¡æ•°
        self.current_frame_counts = {
            'person': 0,
            'bicycle': 0,
            'motorcycle': 0,
            'car': 0,
            'truck': 0,
            'bus': 0,
            'manhole': 0
        }
        
        # æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨ï¼ˆå½“YOLOä¸å¯ç”¨æ—¶ï¼‰
        self.simulation_frame_count = 0

    def calculate_distance(self, point1, point2):
        """è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»ï¼ˆåƒç´ è·ç¦»ï¼‰"""
        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)
    
    def is_near_water(self, person_center):
        """æ£€æŸ¥äººå‘˜æ˜¯å¦åœ¨æ°´åŸŸé™„è¿‘"""
        if not self.water_areas:
            return False
            
        px, py = person_center
        
        for water_area in self.water_areas:
            wx, wy, ww, wh = water_area
            
            # è®¡ç®—äººå‘˜ä¸­å¿ƒç‚¹åˆ°æ°´åŸŸè¾¹ç•Œçš„æœ€çŸ­è·ç¦»
            closest_x = max(wx, min(px, wx + ww))
            closest_y = max(wy, min(py, wy + wh))
            
            distance_pixels = self.calculate_distance((px, py), (closest_x, closest_y))
            
            # å‡è®¾æ¯åƒç´ ä»£è¡¨çº¦0.02ç±³ï¼ˆå¯æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰
            distance_meters = distance_pixels * 0.02
            
            if distance_meters <= self.risk_rules['person']['water_safe_distance']:
                return True
                
        return False
    
    def draw_detection_boxes(self, frame, detections):
        """åœ¨è§†é¢‘å¸§ä¸Šç»˜åˆ¶æ£€æµ‹æ¡†å’Œé£é™©ä¿¡æ¯"""
        overlay_frame = frame.copy()
        
        # é‡ç½®å½“å‰å¸§è®¡æ•°
        self.current_frame_counts = {k: 0 for k in self.current_frame_counts.keys()}
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for detection in detections:
            x = int(detection['x'])
            y = int(detection['y'])
            w = int(detection['width'])
            h = int(detection['height'])
            confidence = detection['confidence']
            class_name = detection['class']
            is_risk = detection.get('risk', False)
            risk_level = detection.get('risk_level', 'ä½')
            
            # æ›´æ–°å½“å‰å¸§è®¡æ•°
            if class_name in self.current_frame_counts:
                self.current_frame_counts[class_name] += 1
            
            # é€‰æ‹©é¢œè‰² (BGRæ ¼å¼)
            if is_risk:
                if risk_level == 'é«˜':
                    color = (0, 0, 255)  # çº¢è‰² - é«˜é£é™©
                else:
                    color = (0, 165, 255)  # æ©™è‰² - ä¸­é£é™©
            elif class_name == 'person':
                color = (0, 255, 0)  # ç»¿è‰² - äººå‘˜
            elif class_name == 'bicycle':
                color = (255, 0, 0)  # è“è‰² - è‡ªè¡Œè½¦
            elif class_name == 'motorcycle':
                color = (255, 0, 128)  # ç´«è“è‰² - æ‘©æ‰˜è½¦/ç”µç“¶è½¦
            elif class_name in ['car', 'truck', 'bus']:
                color = (0, 128, 255)  # æ©™è‰² - æ±½è½¦ç±»
            elif class_name == 'manhole':
                color = (0, 255, 255)  # é»„è‰² - äº•ç›–
            else:
                color = (128, 128, 128)  # ç°è‰² - å…¶ä»–
            
            # ç»˜åˆ¶æ£€æµ‹æ¡†
            thickness = 3 if is_risk else 2
            cv2.rectangle(overlay_frame, (x, y), (x + w, y + h), color, thickness)
            
            # ç»˜åˆ¶æ ‡ç­¾
            label = f"{class_name}"
            if is_risk:
                label += f" [{risk_level}é£é™©]"
                
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            
            # æ ‡ç­¾èƒŒæ™¯
            cv2.rectangle(overlay_frame, 
                         (x, y - label_size[1] - 15), 
                         (x + label_size[0] + 10, y), 
                         color, -1)
            
            # æ ‡ç­¾æ–‡å­—
            cv2.putText(overlay_frame, label, (x + 5, y - 8), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ç»˜åˆ¶æ°´åŸŸåŒºåŸŸï¼ˆå¦‚æœå®šä¹‰äº†ï¼‰
        for water_area in self.water_areas:
            wx, wy, ww, wh = water_area
            cv2.rectangle(overlay_frame, (wx, wy), (wx + ww, wy + wh), (255, 255, 0), 2)
            cv2.putText(overlay_frame, "Water Area", (wx, wy - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯å’Œé£é™©è­¦å‘Š
        self.draw_statistics_overlay(overlay_frame)
        
        return overlay_frame
    
    def draw_statistics_overlay(self, frame):
        """åœ¨å¸§ä¸Šç»˜åˆ¶ç»Ÿè®¡ä¿¡æ¯"""
        h, w = frame.shape[:2]
        
        # èƒŒæ™¯æ¡†
        overlay = frame.copy()
        cv2.rectangle(overlay, (10, 10), (450, 280), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats_text = [
            f"Frame: {self.detection_stats['total_frames']}",
            f"People: {self.current_frame_counts['person']}",
            f"Bicycles: {self.current_frame_counts['bicycle']}",
            f"Motorcycles: {self.current_frame_counts['motorcycle']}",
            f"Cars: {self.current_frame_counts['car']}",
            f"Trucks: {self.current_frame_counts['truck']}",
            f"Buses: {self.current_frame_counts['bus']}",
            f"Manholes: {self.current_frame_counts['manhole']}",
            f"Total Risks: {self.detection_stats['risk_alerts']}"
        ]
        
        for i, text in enumerate(stats_text):
            y_pos = 35 + i * 25
            color = (255, 255, 255)
            
            # äººå‘˜æ•°é‡è¶…è¿‡20æ—¶ç”¨çº¢è‰²æ˜¾ç¤º
            if "People:" in text and self.current_frame_counts['person'] > 20:
                color = (0, 0, 255)
                
            cv2.putText(frame, text, (20, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
        
        # é«˜é£é™©è­¦å‘Š
        if self.current_frame_counts['person'] > 20:
            cv2.putText(frame, "HIGH RISK: >20 PEOPLE!", (20, h - 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 0, 255), 3)
    
    def process_video_to_output(self, input_path, output_path, water_areas=None):
        """å¤„ç†è§†é¢‘æ–‡ä»¶å¹¶è¾“å‡ºå¸¦æ£€æµ‹æ¡†çš„æ–°è§†é¢‘"""
        if not Path(input_path).exists():
            logger.error(f"è¾“å…¥è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
            return False
        
        # è®¾ç½®æ°´åŸŸåŒºåŸŸ
        if water_areas:
            self.water_areas = water_areas
            logger.info(f"è®¾ç½®äº† {len(water_areas)} ä¸ªæ°´åŸŸåŒºåŸŸ")
        
        # æ‰“å¼€è¾“å…¥è§†é¢‘
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            logger.error(f"æ— æ³•æ‰“å¼€è¾“å…¥è§†é¢‘: {input_path}")
            return False
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        logger.info(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}fps, {total_frames}å¸§")
        
        # åˆ›å»ºè¾“å‡ºè§†é¢‘ç¼–å†™å™¨
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        if not out.isOpened():
            logger.error(f"æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘: {output_path}")
            cap.release()
            return False
        
        logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘: {input_path} -> {output_path}")
        
        try:
            frame_count = 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # è¿›è¡Œç›®æ ‡æ£€æµ‹
                detections = self.detect_objects_yolo(frame)
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†å’Œä¿¡æ¯
                output_frame = self.draw_detection_boxes(frame, detections)
                
                # å†™å…¥è¾“å‡ºè§†é¢‘
                out.write(output_frame)
                
                frame_count += 1
                self.detection_stats['total_frames'] = frame_count
                
                # æ˜¾ç¤ºè¿›åº¦
                if frame_count % 30 == 0:
                    progress = (frame_count / total_frames) * 100
                    logger.info(f"å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({progress:.1f}%)")
                    
        except Exception as e:
            logger.error(f"å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {e}")
            return False
        finally:
            cap.release()
            out.release()
        
        logger.info(f"è§†é¢‘å¤„ç†å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {output_path}")
        self.print_final_statistics()
        return True
    
    def process_video_with_realtime_display(self, input_path, output_path=None, water_areas=None):
        """å¤„ç†è§†é¢‘å¹¶å®æ—¶æ˜¾ç¤ºæ£€æµ‹ç»“æœ"""
        if not Path(input_path).exists():
            logger.error(f"è¾“å…¥è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
            return False
        
        # è®¾ç½®æ°´åŸŸåŒºåŸŸ
        if water_areas:
            self.water_areas = water_areas
            logger.info(f"è®¾ç½®äº† {len(water_areas)} ä¸ªæ°´åŸŸåŒºåŸŸ")
        
        # æ‰“å¼€è¾“å…¥è§†é¢‘
        cap = cv2.VideoCapture(input_path)
        if not cap.isOpened():
            logger.error(f"æ— æ³•æ‰“å¼€è¾“å…¥è§†é¢‘: {input_path}")
            return False
        
        # è·å–è§†é¢‘ä¿¡æ¯
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        logger.info(f"è§†é¢‘ä¿¡æ¯: {width}x{height}, {fps}fps, {total_frames}å¸§")
        
        # å¦‚æœæŒ‡å®šäº†è¾“å‡ºè·¯å¾„ï¼Œåˆ›å»ºè§†é¢‘ç¼–å†™å™¨
        out = None
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            if not out.isOpened():
                logger.warning(f"æ— æ³•åˆ›å»ºè¾“å‡ºè§†é¢‘: {output_path}")
                out = None
        
        # åˆ›å»ºæ˜¾ç¤ºçª—å£
        window_name = "æ— äººæœºè§†é¢‘AIæ£€æµ‹ - æŒ‰ESCæˆ–Qé€€å‡º"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(window_name, 1280, 720)  # è®¾ç½®çª—å£å¤§å°
        
        logger.info("å¼€å§‹å®æ—¶æ£€æµ‹ï¼ŒæŒ‰ESCæˆ–Qé”®é€€å‡º...")
        
        try:
            frame_count = 0
            while True:
                ret, frame = cap.read()
                if not ret:
                    logger.info("è§†é¢‘æ’­æ”¾å®Œæ¯•")
                    break
                
                # è¿›è¡Œç›®æ ‡æ£€æµ‹
                detections = self.detect_objects_yolo(frame)
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†å’Œä¿¡æ¯
                output_frame = self.draw_detection_boxes(frame, detections)
                
                # å¦‚æœæœ‰è¾“å‡ºè§†é¢‘ï¼Œå†™å…¥
                if out:
                    out.write(output_frame)
                
                # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                cv2.imshow(window_name, output_frame)
                
                frame_count += 1
                self.detection_stats['total_frames'] = frame_count
                
                # æ˜¾ç¤ºè¿›åº¦
                if frame_count % 30 == 0:
                    progress = (frame_count / total_frames) * 100
                    logger.info(f"å¤„ç†è¿›åº¦: {frame_count}/{total_frames} ({progress:.1f}%)")
                
                # æ£€æŸ¥æŒ‰é”®é€€å‡º
                key = cv2.waitKey(1) & 0xFF
                if key == 27 or key == ord('q') or key == ord('Q'):  # ESCæˆ–Qé”®é€€å‡º
                    logger.info("ç”¨æˆ·æŒ‰é”®é€€å‡º")
                    break
                    
        except KeyboardInterrupt:
            logger.info("æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œåœæ­¢æ£€æµ‹")
        except Exception as e:
            logger.error(f"å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {e}")
            return False
        finally:
            cap.release()
            if out:
                out.release()
            cv2.destroyAllWindows()
        
        if output_path and out:
            logger.info(f"è§†é¢‘å¤„ç†å®Œæˆï¼è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        self.print_final_statistics()
        return True
    
    def print_final_statistics(self):
        """æ‰“å°æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯"""
        logger.info("=== æ£€æµ‹ç»Ÿè®¡æŠ¥å‘Š ===")
        logger.info(f"æ€»å¤„ç†å¸§æ•°: {self.detection_stats['total_frames']}")
        logger.info(f"æ€»æ£€æµ‹å¯¹è±¡: {self.detection_stats['total_detections']}")
        logger.info(f"äººå‘˜æ£€æµ‹æ€»æ•°: {self.detection_stats['person_count']}")
        logger.info(f"è‡ªè¡Œè½¦æ£€æµ‹æ€»æ•°: {self.detection_stats['bicycle_count']}")
        logger.info(f"æ‘©æ‰˜è½¦/ç”µç“¶è½¦æ£€æµ‹æ€»æ•°: {self.detection_stats['motorcycle_count']}")
        logger.info(f"æ±½è½¦æ£€æµ‹æ€»æ•°: {self.detection_stats['car_count']}")
        logger.info(f"å¡è½¦æ£€æµ‹æ€»æ•°: {self.detection_stats['truck_count']}")
        logger.info(f"å…¬äº¤è½¦æ£€æµ‹æ€»æ•°: {self.detection_stats['bus_count']}")
        logger.info(f"äº•ç›–æ£€æµ‹æ€»æ•°: {self.detection_stats['manhole_count']}")
        logger.info(f"é£é™©è­¦æŠ¥æ€»æ•°: {self.detection_stats['risk_alerts']}")
        
        runtime = datetime.now() - self.detection_stats['start_time']
        logger.info(f"æ€»å¤„ç†æ—¶é—´: {runtime}")

    def frame_to_base64(self, frame):
        """å°†è§†é¢‘å¸§è½¬æ¢ä¸ºbase64å­—ç¬¦ä¸²"""
        try:
            # å°†å¸§ç¼–ç ä¸ºJPEG
            _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
            # è½¬æ¢ä¸ºbase64
            frame_base64 = base64.b64encode(buffer).decode('utf-8')
            return frame_base64
        except Exception as e:
            logger.error(f"å¸§è½¬æ¢base64å¤±è´¥: {e}")
            return None
        
    def connect_to_qt(self):
        """è¿æ¥åˆ°Qtåº”ç”¨ç¨‹åºï¼ˆä½œä¸ºTCPå®¢æˆ·ç«¯ï¼‰"""
        max_retries = 10
        retry_delay = 2
        
        for attempt in range(max_retries):
            try:
                self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                self.socket.connect((self.host, self.port))
                logger.info(f"æˆåŠŸè¿æ¥åˆ°Qtåº”ç”¨ç¨‹åº {self.host}:{self.port} (å°è¯• {attempt + 1}/{max_retries})")
                return True
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.info(f"è¿æ¥å¤±è´¥ï¼Œ{retry_delay}ç§’åé‡è¯•... (å°è¯• {attempt + 1}/{max_retries}): {e}")
                    time.sleep(retry_delay)
                else:
                    logger.error(f"æ‰€æœ‰è¿æ¥å°è¯•éƒ½å¤±è´¥äº†: {e}")
                    return False
        return False
    
    def send_detection_results(self, detections, frame=None):
        """å‘é€æ£€æµ‹ç»“æœåˆ°Qtåº”ç”¨ç¨‹åº"""
        if not self.socket:
            return False
            
        try:
            # åˆ›å»ºå¯åºåˆ—åŒ–çš„ç»Ÿè®¡æ•°æ®å‰¯æœ¬
            serializable_stats = self.detection_stats.copy()
            if 'start_time' in serializable_stats:
                serializable_stats['start_time'] = serializable_stats['start_time'].isoformat()
            
            data = {
                'timestamp': datetime.now().isoformat(),
                'frame_id': self.detection_stats['total_frames'],
                'detections': detections,
                'stats': serializable_stats
            }
            
            # å¦‚æœæœ‰å¸§æ•°æ®ï¼Œæ·»åŠ å¸¦æ£€æµ‹æ¡†çš„å›¾åƒ
            if frame is not None and len(detections) > 0:
                overlay_frame = self.draw_detection_boxes(frame, detections)
                frame_base64 = self.frame_to_base64(overlay_frame)
                if frame_base64:
                    data['frame_image'] = frame_base64
                    logger.debug(f"æ·»åŠ æ£€æµ‹æ¡†å›¾åƒï¼Œå¤§å°: {len(frame_base64)} å­—ç¬¦")
            
            json_data = json.dumps(data) + '\n'
            self.socket.send(json_data.encode('utf-8'))
            return True
        except Exception as e:
            logger.error(f"å‘é€æ£€æµ‹ç»“æœå¤±è´¥: {e}")
            return False
    
    def detect_objects_yolo(self, frame):
        """ä½¿ç”¨YOLOè¿›è¡Œç›®æ ‡æ£€æµ‹"""
        if not self.model:
            return self.generate_simulation_detections(frame)
        
        try:
            results = self.model(frame, verbose=False)
            detections = []
            
            # é‡ç½®å½“å‰å¸§æ£€æµ‹è®¡æ•°
            frame_counts = {'person': 0, 'bicycle': 0, 'motorcycle': 0, 'car': 0, 'truck': 0, 'bus': 0, 'manhole': 0}
            
            for result in results:
                boxes = result.boxes
                if boxes is not None:
                    for box in boxes:
                        # è·å–æ£€æµ‹ä¿¡æ¯
                        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                        confidence = box.conf[0].cpu().numpy()
                        class_id = int(box.cls[0].cpu().numpy())
                        
                        # è·å–ç±»åˆ«åç§°
                        class_name = self.model.names[class_id]
                        
                        # æ˜ å°„ä¸ºæˆ‘ä»¬å…³å¿ƒçš„ç±»åˆ«
                        if class_name == 'person':
                            mapped_class = 'person'
                        elif class_name in ['bicycle']:
                            mapped_class = 'bicycle'
                        elif class_name in ['motorcycle', 'motorbike']:
                            mapped_class = 'motorcycle'
                        elif class_name in ['car']:
                            mapped_class = 'car'
                        elif class_name in ['truck']:
                            mapped_class = 'truck'
                        elif class_name in ['bus']:
                            mapped_class = 'bus'
                        # æ³¨æ„ï¼šYOLOé»˜è®¤æ¨¡å‹å¯èƒ½æ²¡æœ‰äº•ç›–ç±»åˆ«ï¼Œè¿™é‡Œä½œä¸ºç¤ºä¾‹
                        elif class_name in ['manhole', 'sewer']:
                            mapped_class = 'manhole'
                        else:
                            continue  # è·³è¿‡å…¶ä»–ç±»åˆ«
                        
                        # è®¡ç®—è¾¹ç•Œæ¡†
                        x, y, w, h = int(x1), int(y1), int(x2-x1), int(y2-y1)
                        center = (x + w//2, y + h//2)
                        
                        # æ›´æ–°å¸§å†…è®¡æ•°
                        frame_counts[mapped_class] += 1
                        
                        # è¯„ä¼°é£é™©
                        is_risk, risk_level = self.assess_risk_new(mapped_class, center, confidence, frame_counts)
                        
                        detection = {
                            'class': mapped_class,
                            'confidence': float(confidence),
                            'x': x,
                            'y': y,
                            'width': w,
                            'height': h,
                            'risk': is_risk,
                            'risk_level': risk_level
                        }
                        
                        detections.append(detection)
                        
                        # æ›´æ–°æ€»ä½“ç»Ÿè®¡
                        self.detection_stats[f'{mapped_class}_count'] += 1
                        
                        if is_risk:
                            self.detection_stats['risk_alerts'] += 1
            
            self.detection_stats['total_detections'] += len(detections)
            return detections
            
        except Exception as e:
            logger.error(f"YOLOæ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def assess_risk_new(self, class_name, center, confidence, frame_counts):
        """æ–°çš„é£é™©è¯„ä¼°æ–¹æ³•"""
        is_risk = False
        risk_level = 'ä½'
        
        if class_name in self.risk_rules:
            rule = self.risk_rules[class_name]
            
            # ç½®ä¿¡åº¦æ£€æŸ¥
            if confidence < rule['confidence_threshold']:
                return False, 'ä½'
            
            # äººå‘˜ç‰¹æ®Šé£é™©è¯„ä¼°
            if class_name == 'person':
                # æ£€æŸ¥äººæ•°æ˜¯å¦è¶…è¿‡30
                if frame_counts['person'] > rule['max_safe_count']:
                    is_risk = True
                    risk_level = 'é«˜'
                
                # æ£€æŸ¥æ˜¯å¦é è¿‘æ°´åŸŸ
                if self.is_near_water(center):
                    is_risk = True
                    risk_level = 'é«˜'
            
            # å¯¹äºä»…ç»Ÿè®¡æ•°é‡çš„ç±»åˆ«ï¼Œä¸æ ‡è®°ä¸ºé£é™©
            elif rule.get('count_only', False):
                is_risk = False
                risk_level = 'ä½'
        
        return is_risk, risk_level
    
    def generate_simulation_detections(self, frame):
     
        detections = []
        self.simulation_frame_count += 1
        
        # æ¨¡æ‹Ÿä¸åŒçš„æ£€æµ‹åœºæ™¯
        frame_cycle = self.simulation_frame_count % 200
        
        # æ¨¡æ‹Ÿäººå‘˜æ£€æµ‹
        if frame_cycle < 50:
            num_persons = random.randint(1, 3)
            for i in range(num_persons):
                x = random.randint(50, 500)
                y = random.randint(100, 300)
                confidence = random.uniform(0.7, 0.95)
                
                is_risk, risk_level = self.assess_risk_new('person', (x, y), confidence, {'person': 0})
                
                detections.append({
                    'class': 'person',
                    'confidence': confidence,
                    'x': x,
                    'y': y,
                    'width': 50,
                    'height': 100,
                    'risk': is_risk,
                    'risk_level': risk_level
                })
                
                self.detection_stats['person_count'] += 1
                if is_risk:
                    self.detection_stats['risk_alerts'] += 1
        
        # æ¨¡æ‹Ÿäº•ç›–æ£€æµ‹
        if frame_cycle % 30 == 0:
            detections.append({
                'class': 'manhole',
                'confidence': random.uniform(0.8, 0.95),
                'x': random.randint(200, 400),
                'y': random.randint(300, 400),
                'width': 60,
                'height': 60,
                'risk': False,
                'risk_level': 'ä½'
            })
        
        # æ¨¡æ‹Ÿç”µç“¶è½¦æ£€æµ‹
        if 80 < frame_cycle < 120:
            confidence = random.uniform(0.75, 0.9)
            x = random.randint(100, 400)
            y = random.randint(200, 350)
            
            is_risk, risk_level = self.assess_risk_new('bicycle', (x, y), confidence, {'bicycle': 0})
            
            detections.append({
                'class': 'bicycle',
                'confidence': confidence,
                'x': x,
                'y': y,
                'width': 80,
                'height': 40,
                'risk': is_risk,
                'risk_level': risk_level
            })
            
            self.detection_stats['bicycle_count'] += 1
            if is_risk:
                self.detection_stats['risk_alerts'] += 1
        
       
        if frame_cycle > 150 and frame_cycle % 50 == 0:
            detections.append({
                'class': 'drowning',
                'confidence': random.uniform(0.85, 0.95),
                'x': random.randint(150, 350),
                'y': random.randint(250, 350),
                'width': 30,
                'height': 30,
                'risk': True,
                'risk_level': 'é«˜'
            })
            
            self.detection_stats['risk_alerts'] += 1
        
        self.detection_stats['total_detections'] += len(detections)
        return detections
    
    def process_video_stream(self, source='simulation', file_path=None):
        """å¤„ç†è§†é¢‘æµ"""
        logger.info(f"å¼€å§‹å¤„ç†è§†é¢‘æµ: {source}")
        
        # è¿æ¥åˆ°Qtåº”ç”¨ç¨‹åº
        if not self.connect_to_qt():
            logger.error("æ— æ³•è¿æ¥åˆ°Qtåº”ç”¨ç¨‹åºï¼Œé€€å‡º")
            return
        
        self.running = True
        cap = None
        
        try:
            # æ ¹æ®æºç±»å‹åˆå§‹åŒ–è§†é¢‘æ•è·
            if source == 'file' and file_path:
                if not Path(file_path).exists():
                    logger.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                    return
                
                cap = cv2.VideoCapture(file_path)
                if not cap.isOpened():
                    logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {file_path}")
                    return
                
                fps = cap.get(cv2.CAP_PROP_FPS)
                total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                logger.info(f"è§†é¢‘æ–‡ä»¶ä¿¡æ¯ - FPS: {fps}, æ€»å¸§æ•°: {total_frames}")
                
                frame_delay = 1.0 / fps if fps > 0 else 1.0 / 30
                
            elif source == 'camera':
                cap = cv2.VideoCapture(0)  # é»˜è®¤æ‘„åƒå¤´
                if not cap.isOpened():
                    logger.error("æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
                    return
                frame_delay = 1.0 / 30
                
            else:  # simulation
                frame_delay = 1.0 / 30
            
            while self.running:
                if source == 'file' and cap:
                    # ä»è§†é¢‘æ–‡ä»¶è¯»å–å¸§
                    ret, frame = cap.read()
                    if not ret:
                        # è§†é¢‘ç»“æŸï¼Œé‡æ–°å¼€å§‹
                        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
                        ret, frame = cap.read()
                        if not ret:
                            logger.error("æ— æ³•ä»è§†é¢‘æ–‡ä»¶è¯»å–å¸§")
                            break
                    
                elif source == 'camera' and cap:
                    # ä»æ‘„åƒå¤´è¯»å–å¸§
                    ret, frame = cap.read()
                    if not ret:
                        logger.error("æ— æ³•ä»æ‘„åƒå¤´è¯»å–å¸§")
                        break
                        
                else:  # simulation
                    # åˆ›å»ºæ¨¡æ‹Ÿå¸§
                    frame = np.zeros((480, 640, 3), dtype=np.uint8)
                    frame.fill(50)  # ç°è‰²èƒŒæ™¯
                    
                    # åœ¨å¸§ä¸Šç»˜åˆ¶ä¸€äº›å†…å®¹
                    cv2.putText(frame, f"Frame: {self.detection_stats['total_frames']}", 
                               (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                    cv2.putText(frame, datetime.now().strftime("%H:%M:%S"), 
                               (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
                
                # ç›®æ ‡æ£€æµ‹
                detections = self.detect_objects_yolo(frame)
                
                # å‘é€æ£€æµ‹ç»“æœï¼ˆåŒ…å«å¸§æ•°æ®ï¼‰
                if detections:
                    self.send_detection_results(detections, frame)
                    logger.info(f"æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡")
                else:
                    # å³ä½¿æ²¡æœ‰æ£€æµ‹ç»“æœï¼Œä¹Ÿå‘é€ç©ºç»“æœä»¥ä¿æŒè¿æ¥
                    self.send_detection_results([], frame)
                
                self.detection_stats['total_frames'] += 1
                
                # æ§åˆ¶å¸§ç‡
                time.sleep(frame_delay)
                
        except KeyboardInterrupt:
            logger.info("æ¥æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œåœæ­¢æ£€æµ‹")
        except Exception as e:
            logger.error(f"è§†é¢‘å¤„ç†å‡ºé”™: {e}")
        finally:
            if cap:
                cap.release()
            self.cleanup()
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.running = False
        if self.socket:
            self.socket.close()
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        runtime = datetime.now() - self.detection_stats['start_time']
        logger.info("æ£€æµ‹ç»Ÿè®¡ä¿¡æ¯:")
        logger.info(f"  è¿è¡Œæ—¶é—´: {runtime}")
        logger.info(f"  æ€»å¸§æ•°: {self.detection_stats['total_frames']}")
        logger.info(f"  æ€»æ£€æµ‹æ•°: {self.detection_stats['total_detections']}")
        logger.info(f"  äººå‘˜æ£€æµ‹: {self.detection_stats['person_count']}")
        logger.info(f"  è½¦è¾†æ£€æµ‹: {self.detection_stats['bicycle_count']}")
        logger.info(f"  é£é™©è­¦æŠ¥: {self.detection_stats['risk_alerts']}")
        
        logger.info("èµ„æºæ¸…ç†å®Œæˆ")

def main():
    """ä¸»å‡½æ•°"""
    # ç›´æ¥åœ¨ä»£ç ä¸­è®¾ç½®è§†é¢‘è·¯å¾„å’Œå‚æ•°
    VIDEO_PATH = r"F:\git\school-aircraft-planner-plugin\resources\video\VID_20250617094821.wmv"
    OUTPUT_PATH = r"F:\git\school-aircraft-planner-plugin\resources\video\VID_20250617094821_analyzed2.mp4"
    
    # å¯é€‰ï¼šè®¾ç½®æ°´åŸŸåŒºåŸŸ (x, y, width, height)
    # å¦‚æœæ‚¨çŸ¥é“è§†é¢‘ä¸­æ°´åŸŸçš„ä½ç½®ï¼Œå¯ä»¥å–æ¶ˆæ³¨é‡Šå¹¶è®¾ç½®åæ ‡
    # WATER_AREAS = [(300, 200, 400, 300)]  # ç¤ºä¾‹åæ ‡ï¼Œéœ€è¦æ ¹æ®å®é™…è§†é¢‘è°ƒæ•´
    WATER_AREAS = []  # æš‚æ—¶ä¸è®¾ç½®æ°´åŸŸåŒºåŸŸ
    
    # è¿è¡Œæ¨¡å¼è®¾ç½®
    SHOW_REALTIME = True  # æ˜¯å¦æ˜¾ç¤ºå®æ—¶æ£€æµ‹çª—å£
    SAVE_VIDEO = True     # æ˜¯å¦ä¿å­˜è¾“å‡ºè§†é¢‘
    
    logger.info("=" * 60)
    logger.info("ğŸš æ— äººæœºè§†é¢‘AIæ£€æµ‹ç³»ç»Ÿ - PyCharmè¿è¡Œæ¨¡å¼")
    logger.info("=" * 60)
    logger.info(f"ğŸ“¹ è¾“å…¥è§†é¢‘: {VIDEO_PATH}")
    logger.info(f"ğŸ’¾ è¾“å‡ºè§†é¢‘: {OUTPUT_PATH if SAVE_VIDEO else 'ä¸ä¿å­˜'}")
    logger.info(f"ğŸ‘ï¸  å®æ—¶æ˜¾ç¤º: {'å¼€å¯' if SHOW_REALTIME else 'å…³é—­'}")
    logger.info(f"ğŸŒŠ æ°´åŸŸåŒºåŸŸ: {len(WATER_AREAS)}ä¸ª")
    logger.info(f"ğŸ¤– YOLOå¯ç”¨: {YOLO_AVAILABLE}")
    
    print("\nâš ï¸  é£é™©è¯„ä¼°è§„åˆ™:")
    print("   â€¢ äººæ•° > 30äºº = é«˜é£é™©(çº¢è‰²)")
    print("   â€¢ è·ç¦»æ°´åŸŸ < 2ç±³ = é«˜é£é™©(çº¢è‰²)")
    print("   â€¢ äº•ç›–å’Œè½¦è¾†ä»…ç»Ÿè®¡æ•°é‡")
    print("   â€¢ æŒ‰ESCæˆ–Qé”®é€€å‡ºå®æ—¶æ˜¾ç¤º")
    print()
    
    # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(VIDEO_PATH).exists():
        logger.error(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {VIDEO_PATH}")
        return
    
    # åˆ›å»ºæ£€æµ‹å™¨
    try:
        logger.info("ğŸ”§ åˆå§‹åŒ–AIæ£€æµ‹å™¨...")
        detector = DroneVideoDetector()
    except Exception as e:
        logger.error(f"âŒ åˆå§‹åŒ–æ£€æµ‹å™¨å¤±è´¥: {e}")
        return
    
    # å¼€å§‹å¤„ç†
    try:
        if SHOW_REALTIME:
            # å®æ—¶æ˜¾ç¤ºæ¨¡å¼
            output_path = OUTPUT_PATH if SAVE_VIDEO else None
            success = detector.process_video_with_realtime_display(
                VIDEO_PATH, output_path, WATER_AREAS
            )
        else:
            # åå°å¤„ç†æ¨¡å¼
            success = detector.process_video_to_output(
                VIDEO_PATH, OUTPUT_PATH, WATER_AREAS
            )
        
        if success:
            logger.info("âœ… å¤„ç†å®Œæˆï¼")
            if SAVE_VIDEO:
                logger.info(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {OUTPUT_PATH}")
        else:
            logger.error("âŒ å¤„ç†å¤±è´¥")
            
    except Exception as e:
        logger.error(f"âŒ ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
    
    logger.info("ğŸ”š ç³»ç»Ÿå·²é€€å‡º")

def main_with_args():
    """å‘½ä»¤è¡Œæ¨¡å¼çš„ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='æ— äººæœºè§†é¢‘AIè¯†åˆ«ç³»ç»Ÿ')
    parser.add_argument('--model', type=str, help='YOLOæ¨¡å‹è·¯å¾„')
    parser.add_argument('--host', type=str, default='localhost', 
                       help='Qtåº”ç”¨ç¨‹åºä¸»æœºåœ°å€')
    parser.add_argument('--port', type=int, default=8888, 
                       help='TCPé€šä¿¡ç«¯å£')
    parser.add_argument('--source', type=str, default='simulation',
                       choices=['simulation', 'camera', 'file', 'process_video'],
                       help='è§†é¢‘æºç±»å‹')
    parser.add_argument('--file', '--file_path', type=str, dest='file_path',
                       help='è§†é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆå½“sourceä¸ºfileæ—¶ä½¿ç”¨ï¼‰')
    parser.add_argument('--input', type=str, help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=str, help='è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--water-areas', type=str, help='æ°´åŸŸåŒºåŸŸåæ ‡ï¼Œæ ¼å¼: "x1,y1,w1,h1;x2,y2,w2,h2"')
    parser.add_argument('--verbose', action='store_true',
                       help='è¯¦ç»†æ—¥å¿—è¾“å‡º')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # å¤„ç†è§†é¢‘æ–‡ä»¶æ¨¡å¼
    if args.source == 'process_video':
        if not args.input or not args.output:
            logger.error("å¤„ç†è§†é¢‘æ¨¡å¼éœ€è¦æŒ‡å®š --input å’Œ --output å‚æ•°")
            return
        
        # è§£ææ°´åŸŸåŒºåŸŸ
        water_areas = []
        if args.water_areas:
            try:
                for area_str in args.water_areas.split(';'):
                    x, y, w, h = map(int, area_str.split(','))
                    water_areas.append((x, y, w, h))
                logger.info(f"è§£æåˆ° {len(water_areas)} ä¸ªæ°´åŸŸåŒºåŸŸ")
            except Exception as e:
                logger.error(f"è§£ææ°´åŸŸåŒºåŸŸå¤±è´¥: {e}")
                return
        
        # åˆ›å»ºæ£€æµ‹å™¨å¹¶å¤„ç†è§†é¢‘
        detector = DroneVideoDetector(model_path=args.model)
        success = detector.process_video_to_output(args.input, args.output, water_areas)
        
        if success:
            logger.info("è§†é¢‘å¤„ç†æˆåŠŸå®Œæˆï¼")
        else:
            logger.error("è§†é¢‘å¤„ç†å¤±è´¥ï¼")
        return
    
    # å‚æ•°éªŒè¯
    if args.source == 'file' and not args.file_path:
        logger.error("å½“è§†é¢‘æºä¸ºæ–‡ä»¶æ—¶ï¼Œå¿…é¡»æŒ‡å®š--file_pathå‚æ•°")
        return
    
    logger.info("å¯åŠ¨æ— äººæœºè§†é¢‘AIè¯†åˆ«ç³»ç»Ÿ")
    logger.info(f"YOLOå¯ç”¨: {YOLO_AVAILABLE}")
    logger.info(f"è¿æ¥å‚æ•°: {args.host}:{args.port}")
    logger.info(f"è§†é¢‘æº: {args.source}")
    if args.file_path:
        logger.info(f"è§†é¢‘æ–‡ä»¶: {args.file_path}")
    
    # åˆ›å»ºæ£€æµ‹å™¨
    detector = DroneVideoDetector(
        model_path=args.model,
        host=args.host,
        port=args.port
    )
    
    # å¼€å§‹å¤„ç†
    try:
        detector.process_video_stream(args.source, args.file_path)
    except Exception as e:
        logger.error(f"ç³»ç»Ÿè¿è¡Œå‡ºé”™: {e}")
    
    logger.info("ç³»ç»Ÿå·²é€€å‡º")

if __name__ == '__main__':
    # æ£€æŸ¥æ˜¯å¦æœ‰å‘½ä»¤è¡Œå‚æ•°
    import sys
    if len(sys.argv) > 1:
        # æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨åŸå§‹çš„å‘½ä»¤è¡Œæ¨¡å¼
        main_with_args()
    else:
        # æ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨PyCharmç›´æ¥è¿è¡Œæ¨¡å¼
        main() 